#!/bin/bash

################################################################################################
### sbatch configuration parameters must start with #SBATCH and must precede any other commands.
### To ignore, just add another # - like so: ##SBATCH
################################################################################################

#SBATCH --partition main			### specify partition name where to run a job. short: 7 days limit; gtx1080: 7 days; debug: 2 hours limit and 1 job at a time
#SBATCH --time 1-03:30:00			### limit the time of job running. Make sure it is not greater than the partition time limit!! Format: D-H:MM:SS
#SBATCH --job-name koyfdan_csv_creator_perfect			### name of the job
#SBATCH --output ./sbatch_out/%A_%a_%J.out			### output log for running job - %J for job number
#SBATCH --ntasks=1
#SBATCH --array=0-1000
#SBATCH --cpus-per-task=4

# Note: the following 4 lines are commented out
#SBATCH --mail-user=koyfdan@post.bgu.ac.il	### user's email for sending job status messages
#SBATCH --mail-type=FAIL			### conditions for sending the email. ALL,BEGIN,END,FAIL, REQUEU, NONE
#SBATCH --mem=6G				### ammount of RAM memory

### Print some data to output file ###
echo `date`

echo -e "
SLURM_JOBID:		" $SLURM_JOBID
echo -e "SLURM_JOB_NODELIST:	" $SLURM_JOB_NODELIST "

"
### Start your code below ####
module load anaconda				### load anaconda module (must be present when working with conda environments)
source activate danny_env				### activate a conda environment, replace my_env with your conda environment.

###prev runs: 0 1001 2002 3003 4004 5005 6006 7007 8008 9009 10010 11011 12012 13195 14196 15197 16198 17199 18200 19201 20202 21393 22394+5 23400 24402 25403 26404 27405 28406 29407 30408 31409 32410 33411 34412 35413 36414 37415 38416 39417 40418 41419 42420 43421 44422 45423 46424 47425 48426###
start_index=48426
curr_index=$(($SLURM_ARRAY_TASK_ID+$start_index))


task_line="$(sed "$curr_index q;d" ./instances_2)"
out_file=""./output_files/"$SLURM_ARRAY_JOB_ID"_"$curr_index"".out"


echo $curr_index
python /home/koyfdan/corner_search/run_maps.py $task_line --algorithm 0 --out-file "$out_file" &
python /home/koyfdan/corner_search/run_maps.py $task_line --algorithm 1 --out-file "$out_file" &
python /home/koyfdan/corner_search/run_maps.py $task_line --algorithm 2 --out-file "$out_file" &
python /home/koyfdan/corner_search/run_maps.py $task_line --algorithm 3 --out-file "$out_file" &

wait
###